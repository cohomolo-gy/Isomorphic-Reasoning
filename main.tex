\documentclass[tikz]{beamer}

\usepackage{minted}
\usepackage{eucal,mathrsfs}
\usepackage{tikz-cd}
\usepackage{amsfonts}
\usepackage{enumerate}
\usetheme{Darmstadt}
\colorlet{shadecolor}{gray!15}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\newcommand{\propnumber}{} % initialize
\newtheorem*{prop}{Proposition \propnumber}
\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]

\newcommand{\cat}[1]{\mathbf{#1}}
\newcommand{\homf}[2]{[\cat{#1}, \cat{#2}]}

\title{Isomorphic Reasoning: Counting Polymorphic Type Inhabitants}
\author{Emily Pillmore, Alexander Konovalov}
\date{May 2019}

\begin{document}
\maketitle

\section{Introduction}
\subsection{}

\begin{frame}{Who are we?}

But who are we and what do we do?

\end{frame}

\begin{frame}{Why this workshop?}
\begin{itemize}
    \item Learn you a \textbf{good deal of Category Theory}, $\lambda$-calculus, and Type Theory.
    \item Learn powerful techniques to think about types and programs.
    \item Learn how to rigorously show that $\forall a. a \rightarrow a$ has only one inhabitant.
    \item Learn a different way of thinking about \textit{free}-theorems and properties.
    \item Learn how to rigorously show that \textbf{ap} is the same as \textbf{zip}.
\end{itemize}
% But who are we and what do we do?
\end{frame}

\begin{frame}{Why isomorphic reasoning?}
We often get overly hyped about a new functional technique not realizing that it is the same old idea, just with a different flavor. 

Seeing such connections between ideas will make you a better developer.
\end{frame}

\begin{frame}{Why count type inhabitants?}
For compiler writers: Knowing that a type $T$ has only one inhabitant $\textbf{simple} : T$ allows us to simplify any complicated $\textbf{complex} : T$ and replace it with $\textbf{simple} : T$.
\end{frame}

\begin{frame}{Why count type inhabitants?}
For IDE writers: 
\begin{itemize}
    \item If we can find the number of inhabitants, we can (likely) also enumerate them. This allows for type-based auto-completion up to \textbf{observational equivalence}.
    \item If we know that there are no inhabitants, we (likely) have a constructive proof of that, which means we can either auto-complete functions $0 \rightarrow a$, or we can outright allow the user to say ``this is impossible'', like Idris does.
\end{itemize}

\end{frame}

\begin{frame}{Why count type inhabitants?}
Proving that a type $P$ has inhabitants is equivalent to proving the theorem corresponding with $P$ due to Curry-Howard-Lambek correspondence.
\end{frame}

\begin{frame}{Why count type inhabitants?}

So what do we mean by counting?

\end{frame}

\begin{frame}{Why count type inhabitants?}

When are two things equal? 

\begin{itemize}
	\item 1729 
	\item $12^3 + 1$
	\item ``the first number expressible as a sum of two cubes in two different ways''
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Expressions}

If 1729 and $12^3+1$ are expressions, they are different.

\end{frame}

\begin{frame}[fragile]{Expressions}

\begin{minted}{haskell}
data Expr = Lit Int | Add Expr Expr | Pow Expr Expr

first  = Lit 1729
second = Add (Pow (Lit 12) (Lit 3)) (Lit 1)
\end{minted}
\end{frame}

\begin{frame}[fragile]
If 1729 and $12^3+1$ are integers, they are the same.
    
\end{frame}

\begin{frame}[fragile]{Expressions}

\begin{minted}{haskell}
first :: Int
first  = 1729
second :: Int
second = 12^3 + 1
\end{minted}
\end{frame}


\begin{frame}
\begin{block}{Gottfried Wilhelm Leibniz, 1646-1716:}
For any x and y, if x is identical to y, then x and y have all the same properties.
For any x and y, if x and y have all the same properties, then x is identical to y.
\end{block}
\end{frame}

\begin{frame}

$x = y \Leftrightarrow \forall P. P x \leftrightarrow P y$ where $P$ is quantified over all properties of an object.

\end{frame}


\begin{frame}

\begin{itemize}
\item We can't see the difference of them as values within a pure functional language. 
\item We can see the difference between the actual expression trees.
\item We don't really care about the latter as since it does not affect the semantics.
\end{itemize}

\end{frame}


\begin{frame}{But How?}
    How does this apply to functional programming? category theory? 
    
    
\end{frame}{}

\begin{frame}{But How?}
    
 Lets look at an example   
    
\end{frame}{}

\begin{frame}{Examples of enumeration}
    
    \begin{itemize}
    	\item Bool = $T \lor F$ has precisely 2 values - true of false.
	\item tuples
	\item either
	\item maybe
	\item $\to$
    \end{itemize}
    
\end{frame}{}

\begin{frame}{Isomorphisms}
	\begin{itemize}   
	\item So far we've been enumerating things. 
	\item But enumeration is essentially an isomorphism to a finite set.
	\end{itemize}
\end{frame}

\begin{frame}{Isomorphisms}
	For instance enumerating the elements of \textbf{Bool} gives an bijection (an isomorphism of sets) to a set with 2 elements $\{\top, \perp\}$. 
\end{frame}

\begin{frame}[fragile]{Isomorphisms}
An isomorphism is a pair of two functions, $\mathbf{to}: A \to B$ and $\mathbf{from}: B \to A$, such that $\mathbf{to} \cdot \mathbf{from} = id_B$ and $\mathbf{from} \cdot \mathbf{to} = id_A$.
    
\begin{minted}{haskell}
data Iso a b = Iso {
  to   :: a -> b
  from :: b -> a
  -- fromTo :: (x :: a) -> (from . to) x = x
  -- toFrom :: (x :: b) -> (to . from) x = x
}
\end{minted}
\end{frame}

\begin{frame}[fragile]{Isomorphisms preserve equality}
So why are we interested in isomorphisms?

\begin{block}{Equality Preservation}
    If $A$ and $B$ are isomorphic, and $a_1: A, a_2: A$ map to $b_1: B, b_2: B$ respectively, then $a_1 = a_2 \iff b_1 = b2$.
\end{block}
\end{frame}

\begin{frame}[fragile]
We can prove it very easily:

\begin{align*}
    a_1 &= a_2 \\ 
    \text{to}~a_1 &= \text{to}~a_2 \\
    b_1 &= b_2 \\
    \text{from}~b_1 &= \text{from}~b_2 \\
    a_1 &= a_2 \\
\end{align*}

Note that this proof will work regardless of what we mean by $=$, as long as it is preserved by function application: $a = b \Rightarrow f~a = f~b$.
\end{frame}

\begin{frame}[fragile]
But for observational equivalence, equality preservation is almost literally built into the definition!

\begin{center}
    $a = b \iff \forall P. (P~a \leftrightarrow P~b)$
\end{center}
\end{frame}


\begin{frame}[fragile]
Note that this does not hold for \textbf{Eq} as found in Haskell, because equality is not preserved for floating point numbers:
\begin{minted}{haskell}
woops :: Float -> Bool
woops x = (1 / x) > 0
comparison = woops +0.0 == woops -0.0
\end{minted}
\end{frame}


\begin{frame}[fragile]
Since equality is preserved by isomorphisms, so is the number of inhabitants:

\begin{block}{Inhabitant Count Preservation}
If $A$ and $B$ are isomorphic, then they have the same number of inhabitants.
\end{block}
\end{frame}

\begin{frame}[fragile]{More isomorphism examples}
Let's see some interesting isomorphisms.
    
\begin{minted}{haskell}
leftUnitP :: Iso ((), a) a
leftUnitP = Iso (\((), a) -> a)
                (\a -> ((), a))

commuteP :: Iso (a, b) (b, a)
commuteP = Iso (\(a, b) -> (b, a))
               (\(b, a) -> (a, b))
              
associateP :: Iso ((a, b), c) (a, (b, c))
associateP = Iso (\((a, b), c) -> (a, (b, c)))
                 (\(a, (b, c)) -> ((a, b), c))
\end{minted}
\end{frame}

\begin{frame}[fragile]
What does this remind you of?
    
\begin{minted}{haskell}
rightUnitP  :: Iso (a, ()) a
leftUnitP   :: Iso ((), a) a
associateP  :: Iso ((a, b), c) (a, (b, c))
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}{haskell}
leftUnitC :: Iso (Either Void a) a
leftUnitC = ...
commuteC :: Iso (Either a b) (Either b a)
commuteC = ...
              
associateC :: Iso (Either (Either a b) c) 
                  (Either a (Either b c))
associateC = 
  Iso (\case Left (Left a)  -> Left a;
             Left (Right b) -> Right (Left b);
             Right c        -> Right (Right c))
      (\case Left a          -> Left (Left a);
             Right (Left b)  -> Left (Right b);
             Right (Right c) -> Right c)
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}{haskell}
currying :: Iso ((a, b) -> c) (a -> b -> c)
currying = Iso (\f -> \a -> \b -> f (a, b))
               (\f -> \case (a, b) -> f a b)
               
leftUnitF :: Iso (() -> a) a
leftUnitF = Iso (\f -> f ()) (\a -> \_ -> a)

rightUnitF :: Iso (a -> ()) ()
rightUnitF = Iso (\_ -> ()) (\_ -> \_ -> ())
\end{minted}
\end{frame}

\begin{frame}[fragile]
Let's take a leap of faith here, and replace (a, b) with $a \times b$, Either a b with $a + b$, $a \rightarrow b$ with $b^a$, () with 1, Void with 0, and Iso a b with $a \cong b$, for example:

\begin{minted}[escapeinside=||,mathescape]{haskell}
foo :: Iso (Either Void ((), a)) a
foo :: (0 + (1 |$\times$| a)) |$\cong$| a
\end{minted}
\end{frame}



\begin{frame}[fragile]
What does this look like?

\begin{minted}[escapeinside=||,mathescape]{haskell}
leftUnitP  :: (|$1$| |$\times$| a) |$\cong$| a
commuteP   :: (a |$\times$| b) |$\cong$| (b |$\times$| a)
associateP :: ((a |$\times$| b) |$\times$| c) |$\cong$| (a |$\times$| (b |$\times$| c))
leftUnitC  :: (|$0$| + a) |$\cong$| a
commuteC   :: (a + b) |$\cong$| (b + a)
associateC :: ((a + b) + c) |$\cong$| (a + (b + c))
currying   :: |$c^{a \times b}$| |$\cong$| |$(c^b)^a$|
leftUnitF  :: |$a^1$| |$\cong$| a
rightUnitF :: |$1^a$| |$\cong$| |$1$|
\end{minted}
\end{frame}

\begin{frame}[fragile]
Let's see if our intuition is right. Convince yourself that you can construct these:

\begin{minted}[escapeinside=||,mathescape]{haskell}
distribute :: Iso (a, Either b c) (Either (a, b) (a, c))
distribute :: (a, b + c) |$\cong$| ((a |$\times$| b) + (a |$\times$| c))

-- Hint: use identity of indiscernibles
introVoid :: Iso (Void -> a) ()
introVoid :: |$a^0$| |$\cong$| 1

-- This will turn out to be a very useful isomorphism
pairing :: Iso (Either a b -> c) (a -> c, b -> c)
pairing :: |$c^{a + b}$| |$\cong$| |$c^a \times c^ b$|
\end{minted}
\end{frame}

\begin{frame}{The type algebra}
There is a correspondence between categories, types, sets, and sets of natural numbers.

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Types & Sets & Naturals & Categories \\
\hline
a       & $A$ & $|A|$  & $A \in \cat{C}$ \\
(a, b) & $A \times B$ & $|A| \times |B|$ & $A \otimes B$ \\
Either a b & $A \sqcup B$ & $|A| + |B|$ & $A \oplus B$ \\
$a \to b$ &  set functions & $|B|^{|A|}$ & $f \in \cat{C}(A, B)$ \\ 
() & $\{*\}$ & 1 & terminal objects \\
Void & $\emptyset$ & 0 & initial objects \\ \hline 
\end{tabular}
\end{center}
\end{frame}
    

\begin{frame}{Goals}
    
    In functional programming we work with a subtle form of arithmetic every day, but it's rare that we actually \textit{understand} what it is we're doing. It turns out to be a very deep process with a very intuitive facade! 
    
\end{frame}

\begin{frame}{Steps}
    
    What does it mean to have this correspondence? We will the language of category theory to build the formalism using the following steps: 
    
\begin{itemize}
    \item Step 0: Preliminary definitions
    \item Step 1: (De-)categorification
    \item Step 2: The Yoneda Lemma
    \item Step 3: Representability
    \item Step 4: Proofs of examples
\end{itemize}
    
And optionally if we have time, 
\begin{itemize}
    \item Step 5: Adjunctions, Limits, Colimits
    \item Step 6: A Proof Using LAPC, RAPL
\end{itemize}
\end{frame}

\begin{frame}{Steps}
    
    Then, we will count! Lets get started with the preliminaries.
\end{frame}

\section{Preliminaries}
\subsection{}
\begin{frame}{Definitions}
\begin{definition}[Category]
A \textbf{Category} consists of the following data:
\begin{itemize}
    \item a collection of \textbf{objects} $x, y, z, \ldots$
    \item a collection of \textbf{morphisms} $f, g, h, \ldots$
\end{itemize}{}
 such that 
\begin{itemize}
    \item each morphism has specified \textbf{domain} and \textbf{codomain} objects. The notation $f: x \to y$ signifies that the morphism $f$ has domain $x$ and codomain $y$
    \item each object has an associated \textbf{identity morphism} $1_x : x \to y$
    \item For any pair of morphisms $f: x \to y, g: y \to z$ there exists a morphism $gf: x \to z$
\end{itemize}{}

\end{definition}
\end{frame}
\begin{frame}{Definitions}

This data is subject to the following axioms: 

\begin{itemize}
    \item For any $f: x \to y$, the composites $1_y f$ and  $f 1_x$ are both equal to $f$
    \item For any composable triple $f, g, h$, the composites $h(gf)$ and $(hg)f$ are equal, and we will simply denote them $hgf$.
    \item Between any two objects $x, y$ in the category $\mathbf{C}$, we may speak of the collection of morphisms with domain $x$ and codomain $y$ called $Hom_{\mathbf{C}}(x, y)$. Sometimes, we will denote this object $\mathbf{C}(X, Y)$ for ease of use.
\end{itemize}{}

This is to say that the law of composition is \textit{associative} and \textit{unital} with the morphisms $1_{(-)}$  serve as two-sided identities 
\end{frame}

\begin{frame}{Definitions}
\begin{enumerate}[i]
    \item \textbf{Set} has sets as its objects, and functions with specified domain and codomain as morphisms
    \item \textbf{Pos} has partially-ordered sets as objects and order-preserving functions as morphisms
    \item \textbf{Top} has topological spaces as objects and continuous functions as morphisms
    \item \textbf{Mon} has the single point set $1$ as its only object, and its morphisms are the elements of the monoid with composition given by the monoid operation.
    \item \textbf{Hask}... (just kidding)
\end{enumerate}{}
\end{frame}
\begin{frame}{Definitions}
    All of these are examples of concrete categories - categories in which the collection of objects and collection of morphisms are both \textit{sets}. However, there are categories with in which one or more of these collections is larger than sets (like the category of categories), so we must introduce some subtlety to the theory in order to avoid category-theoretic versions of Russel's paradox in inopportune places. 
\end{frame}{}
\begin{frame}{Definitions}
    Lets introduce a few definitions that we'll use sparingly when in need:
    
\begin{definition}

A category $\mathbf{C}$ is...
\begin{itemize}
    \item \textbf{concrete} if its collection of objects and morphisms are both sets.
    \item  \textbf{small} if only its collection of morphisms is a set.
    \item \textbf{locally small} if for any two objects $x$ and $y$, $\mathbf{C}(x, y)$  is a set.
\end{itemize}{}
\end{definition}

For our purposes, when working with types, we are usually working in a concrete category, if not $\mathbf{C}$ directly. 
\end{frame}
 
\begin{frame}{Definitions}
    \begin{definition}
        For every category $\mathbf{C}$ we may speak about its \textbf{dual} notion $\mathbf{C}^{op}$, the \textbf{opposite category} of $\mathbf{C}$, which consists of the following data: 
        \begin{itemize}
            \item the same objects as $\mathbf{C}$
            \item a morphism $f^{op}$ in $\mathbf{C}^{op}$ for each morphism $f$ in $\mathbf{C}$ with the codomain and domain reversed. i.e. when $f: x \to y$, $f^{op} : y \to x$.
        \end{itemize}{}
    \end{definition}{}
\end{frame}{}


\begin{frame}{Definitions}
The data described in the previous slide defines a category in relation to itself. The process of "turning around the arrows" or "swapping domains and codomains" exhibits a syntactic self-duality for every category, retaining the precisely the same information as $\mathbf{C}$. In this way, we have a unique perspective in Category Theory: For every theorem proven in general for a category, we immediately prove its dual, since the opposite category is a valid category in its own right. More generally, if one proves theorems "for all categories $\mathbf{C_1}, \mathbf{C_2}, \ldots , \mathbf{C_n}$", then this leads to $2^n$ dual theorems. In practice though, these dual theorems do not differ meaningfully from the original.
    
\end{frame}{}

\begin{frame}{Definitions}
    We will now introduce the types of morphisms you will encounter in the wild. Much like the injective/bijective/surjective functions on sets that we are used to, we have abstract version notions of these concepts.
\end{frame}{}

\begin{frame}{Definitions}
    \begin{definition}[Isomorphism]
       An \textbf{isomorphism} in a category is a morphism $f: x \to y$ for which there exists a morphism $g: y \to x$ such that $gf = 1_x$ and $fg = 1_y$ ($g$ is a two-sided inverse). The objects $x$ and $y$ are said to be \textbf{isomorphic}, and we denote this $x \cong y$. 
    \end{definition}
    
\end{frame}{}

\begin{frame}{Definitions}

    \begin{definition}[Functor]
        A \textbf{functor} $F: \mathbf{C} \to \mathbf{D}$ between categories $\mathbf{C}$ and $\mathbf{D}$ consists of the following data: 
        
        \begin{itemize}
            \item An object $Fc \in \mathbf{D}$ for each object $c \in \mathbf{C}$
            \item A morphism $Ff: Fc \to Fc'$ in \textbf{D} for each morphism $f \in \mathbf{C}$
        \end{itemize}{}
    \end{definition}{}
    
Additionally, the following must be satisfied: 
\begin{itemize}
    \item For any composable pair $f, g$ in $\mathbf{C}$, $Fg \cdot Ff = F(g \cdot f)$
    
    \item For each object $c \in \mathbf{C}$, $F(1_c) = 1_{Fc}$     
\end{itemize}
\end{frame}

\begin{frame}{Definitions}

So far, we have defined a functor which acts uniformly on arrows. However, there exist functors which have a tendency to take arrows in the source category and flip the direction of the arrows such that they point the opposite way in the target category i.e. for any such functor $F: \mathbf{C} \to \mathbf{D}$ and any objects $c, c'$ and morphism $f: c \to c'$ in \textbf{C}, we have $Ff: Fc' \to Fc$. Such functors are called \textbf{contravariant} functors, in contrast to their siblings which are called \textbf{covariant}.
    
\end{frame}

\begin{frame}{Definitions}

Instead of differentiating each functor by variance, note that every contravariant functor is a covariant functor $F: \mathbf{C}^{op} \to \mathbf{D}$. Instead of juggling variance, we will simply be sure to specify the variance of a functor by whether or not it maps from an opposite category.
    
\end{frame}

\begin{frame}{Definitions}

    \begin{itemize}
        \item The power set functor $P: \mathbf{Set} \to \mathbf{Set}$ that sends a set $A$ to its power set $PA = \{U : U \subset A\}$ and a function $f: A \to B$ to the direct image function $f_* : PA \to PB$ which sends $U \subset A$ to $f_*(U) \subset B$
        
        \item The contravariant power set functor $P: \mathbf{Set}^{op} \to \mathbf{Set}$ sends a set $A$ to its power set $PA$, and every function $f: A \to B$ to the inverse-image function $f^{-1}: PB \to PA$ such that $V \subset B \mapsto f^{-1}(V) \subset A$.
    \end{itemize}{}
\end{frame}{}

\begin{frame}{Definitions (cont'd)}

\begin{itemize}
    \item For any $c \in \mathbf{C}$ the covariant Hom-functor $\mathbf{C}(c, -): \mathbf{C} \to \mathbf{C}$ taking objects in $\mathbf{C}$ to their corresponding hom-sets in \textbf{Set}, and morphisms to post-composition.
    \item For any $c \in \mathbf{C}^{op}$ the contravariant Hom-functor $\mathbf{C}(-, c): \mathbf{C}^{op} \to \mathbf{C}$ taking objects in $\mathbf{C}$ to their corresponding hom-sets in \textbf{Set} and morphisms to pre-composition. 
\end{itemize}{}
\end{frame}{}

\begin{frame}{Definitions (cont'd) }

\begin{definition}[Initial and Terminal objects]

An object $c \in \cat{C}$ is called \textbf{terminal}, if for all other objects in $c' \in \cat{C}$, there exists a single unique (up to isomorphism) morphism $c' \to c$. Dually, an object is called \textbf{initial} if there exists a single unique (up to isomorphism) morphism from $c$ to any other $c' \in \cat{C}$.  
\end{definition}
\end{frame}

\begin{frame}{Definitions (cont'd) }

\begin{itemize}
	\item In $\cat{Set}$, the singleton set $\{*\}$ is terminal and the empty set $\emptyset$ is initial. 
	\item In the categories $\cat{Grp}$ of groups and group homomorphisms and $\cat{Mon}$ of monoids and monoid homomorphisms, the trivial group/monoid $1$ is both initial and terminal
	\item 
\end{itemize}
\end{frame}

\begin{frame}[fragile]
    
    \begin{definition}[Natural Transformation]
        A \textbf{natural transformation} between two functors $F,G: \mathbf{C} \to \mathbf{D}$ consists of the following data: 
        
        \begin{itemize}
            \item To each $c \in C$, a component morphism $\alpha_c : Fc \to Gc$ exists such that the following diagram commutes or any $c, c' \in \mathbf{C}$ and $f: c \to c'$:
            \begin{center}
                \begin{tikzcd}
                    Fc 
                      \ar[r, "\alpha_c"]
                      \ar[d, "Ff"]
                    & Gc \ar[d, "Gf"] \\
                    Fc' \ar[r, "\alpha_{c'}"]
                    & Gc'
            \end{tikzcd}{}
            \end{center}{}
        \end{itemize}{}
        
    \end{definition}{}
 
 There is such a thing as a \textbf{natural isomorphism} as well. How might you define one?
\end{frame}

\begin{frame}[fragile]
    
    \begin{definition}[Natural Transformation]
        A \textbf{natural transformation} between two functors $F,G: \mathbf{C} \to \mathbf{D}$ consists of the following data: 
        
        \begin{itemize}
            \item To each $c \in C$, a component morphism $\alpha_c : Fc \to Gc$ exists such that the following diagram commutes or any $c, c' \in \mathbf{C}$ and $f: c \to c'$:
            \begin{center}
                \begin{tikzcd}
                    Fc 
                      \ar[r, "\alpha_c"]
                      \ar[d, "Ff"]
                    & Gc \ar[d, "Gf"] \\
                    Fc' \ar[r, "\alpha_{c'}"]
                    & Gc'
            \end{tikzcd}{}
            \end{center}{}
        \end{itemize}{}
        
    \end{definition}{}
    
    \begin{definition}[natural isomorphism]
      A \textbf{natural isomorphism} is a natural isomorphism where each component is an isomorphism. We'll denote them as $\alpha: F \cong G$.
    \end{definition}{}
\end{frame}

\begin{frame}{Definitions}

In effect, this means that the following naturality condition holds for all $c, c' \in \mathbf{C}$ for a given transformation $\alpha: F \Rightarrow G$: 

\begin{center}
    \begin{equation*}
        \alpha_{c'}F = G \alpha_c
    \end{equation*}{}
\end{center}{}
\end{frame}

\begin{frame}{Definitions}
    This is called a \textit{naturality} condition. To say that $\alpha$ is \textit{natural} in $c$ is to say there exists a component morphism $\alpha_c$ providing a relationship between $Fc$ and $Gc$.
\end{frame}

\begin{frame}{Definitions}
    In other words, if you think of functors as containers of values, natural transformations modify the shape of the container, but does not modify its contents. In some sense, the components of a natural transformation are orthogonal to functor maps. If you imagine $F \Rightarrow F$, then the components of such a transformation correspond with permutations of $F$.
\end{frame}

\begin{frame}{Definitions}
    Natural transformations are ubiquitous. In a sense, they form "analogies between relationships". If one takes the perspective that functors define an intimate relationship between structures, then natural transformations provide a way of relating those relationships.
\end{frame}

\begin{frame}{Definitions}
    Examples of natural transformations appear everywhere in the wild. Here are a few: 
    
    \begin{itemize}
        \item There is a natural transformation $\eta_A : 1_{\mathbf{Set}} \Rightarrow P$ from the identity to the covariant power set functor whose components $\eta_A : A \to PA$ are functions that carry $a \in A$ to ${a} \in PA$.
        
        \item The open and closed subset functors are naturally isomorphic when regarded as functors $\mathcal{O},\mathcal{C}: \mathbf{Top}^{op} \to \mathbf{Set}$. The components are defined by taking an open subset of $X$ to its complement, which is closed. Thus, the "naturality" condition asserts that forming complements commutes with taking preimages (i.e. $f^{-1}(V)^c \cong f^{-1}(V^c)$).
    \end{itemize}{}
\end{frame}

\section{Categorification}
\subsection{}

\begin{frame}{Categorification}
    What is \textbf{(de-)categorification}?
   
\end{frame}

\begin{frame}{Categorification}
A process by which set-theoretic concepts are expressed in terms of category theory, or concepts in category theory to higher category theory.

\end{frame}

\begin{frame}{Categorification}
    Lets begin by looking at the relationship between sets, categories, and arithmetic in the natural numbers.
\end{frame}{}

\begin{frame}{Categorification}

Let's revisit our table.


\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Types & Sets & Naturals & Categories \\
\hline
a       & $A$ & $|A|$  & $A \in \cat{C}$ \\
(a, b) & $A \times B$ & $|A| \times |B|$ & $A \otimes B$ \\
Either a b & $A \sqcup B$ & $|A| + |B|$ & $A \oplus B$ \\
$a \to b$ &  set functions & $|B|^{|A|}$ & $f \in \cat{C}(A, B)$ \\ 
() & $\{*\}$ & 1 & terminal objects \\
Void & $\emptyset$ & 0 & initial objects \\ \hline 
\end{tabular}
\end{center}

\end{frame}

\begin{frame}{Categorification}
    What is a natural number?
\end{frame}

\begin{frame}{Categorification}
One way to represent the natural numbers is as cardinalities of finite sets.

\begin{center}
        \begin{equation*}
            a :\equiv |A| \qquad b :\equiv |B| \qquad c :\equiv |C|
        \end{equation*}
\end{center}
\end{frame}

\begin{frame}{Categorification}
What is true when $a = b$?
\end{frame}

\begin{frame}{Categorification}
If we use the representation that natural numbers correspond with the cardinality of finite sets, 
then there is a correspondence between equality of natural numbers, and equivalence classes of isomorphisms of  
finite sets.
\end{frame}

\begin{frame}{Categorification}
In fact, isomorphism classes of finite sets form a subcategory  $\cat{Fin_{Iso}}$ of $\cat{Set}$ with objects as isomorphism classes and morphisms as isomorphisms.
\end{frame}

\begin{frame}{Categorification}
The taking of cardinalities constructs a functor $|-|\colon \cat{Fin_{Iso}} \to \cat{Set}$ taking isomorphism classes to a set whose elements are in bijection with a subset of the natural numbers.
\end{frame}

\begin{frame}{Categorification}
    It's natural now, to also ask about multiplication and addition of natural numbers.
\end{frame}

\begin{frame}{Categorification}
    Lets apply the same sort of categorification.
    
\end{frame}

\begin{frame}{Categorification}

What sets have size $a \times b$,  $b + c$ and $c^d$?

\end{frame}{}

\begin{frame}{Categorification}

By counting, 
    \begin{itemize}
        \item $|A \times B| \cong a \times b$
        \item $|B \sqcup C| \cong b + c$.
        \item $|C^D| \cong c ^ d$
    \end{itemize}
\end{frame}{}


\begin{frame}{Categorification}

So what is the nature of (de-)categorification?

\end{frame}

\begin{frame}{Categorification}

It establishes a correspondence between objects in a category with objects in $\cat{Set}$ (or vice versa).

\end{frame}


\begin{frame}{Categorification}

Summary: 

\begin{align*}
    A \times B \Rightarrow a \times b &\leftrightsquigarrow |A \times B| \cong a \times b \\
    B \sqcup C \Rightarrow b + c &\leftrightsquigarrow |B \sqcup C| \cong b + c \\
    C^D \Rightarrow c^d &\leftrightsquigarrow |C|^{|D|} \cong c^d
\end{align*}
\end{frame}

\begin{frame}{Categorification}
    
    So what does this correspond to?
    
    \begin{block}{}
        $a \times (b + c) = (a \times b) + (a \times c) $
    \end{block}{}
\end{frame}{}

\begin{frame}{Categorification}
    
    So what does correspond to?
    
    \begin{block}{}
        $a \times (b + c) = (a \times b) + (a \times c) $
    \end{block}{}
 
 Answer:

\begin{block}{}
    $A \times (B + C) \cong (A \times B) \sqcup (A \times C)$
\end{block}{}
 
\end{frame}{}

\section{Yoneda Lemma}
\subsection{}
\begin{frame}{Yoneda}
    
\begin{block}{A perspective:}
    An objects is fully determined by its relationship to other objects.
\end{block}{}


\end{frame}

\begin{frame}{Yoneda}
    
    
\begin{block}{Translation:}
    An object is fully determined by the morphisms and to and from the object.
\end{block}{}

\end{frame}

\begin{frame}{Yoneda}
    
Q: But why is this important? Why do we care?
\end{frame}

\begin{frame}
To quote from a friend: 
\begin{block}{}
    "Most statements in elementary category theory can be proved using some variant statement of yoneda together with information about the category of sets"
\end{block}{}

\end{frame}



\begin{frame} 
\begin{block}{The Yoneda Lemma}
    $A$ and $B$ are isomorphic if and only if 
    \begin{itemize}
        \item For all $X$, $\mathbf{C}(A, X) \cong \mathbf{C}(B, X)$
        
        \item the isomorphisms $\mathbf{C}(A, X) \cong \mathbf{C}(B, X)$ are \textit{natural} with respect to any function $f : X \to Y$.
    \end{itemize}{}
\end{block}{}



\end{frame}
\begin{frame}{Yoneda}
    Q: But what does this mean?
    
\end{frame}
\begin{frame}{Yoneda}
    \begin{block}{The Yoneda Lemma}
        $A$ and $B$ are isomorphic if and only if the functors $\mathbf{C}(A, -) $ and $\mathbf{C}(B, -)$ are naturally isomorphic.
    \end{block}{}
\end{frame}

\begin{frame}{Yoneda}
    \begin{block}{The Yoneda Lemma}
        $A$ and $B$ are isomorphic if and only if the functors $\mathbf{C}(A, -) $ and $\mathbf{C}(B, -)$ are naturally isomorphic.
    \end{block}{}
    
    \begin{proof}[Proof ($\Leftarrow$)]
    
        Let $\mathbf{C}(A, X) \cong \mathbf{C}(B, X)$ for every $X$. Let $X = A$, and $X = B$. Then, we prove this using the following bijections and a diagram chase (see board): 
        
        \begin{equation*}
            \mathbf{C}(A, A) \cong \mathbf{C}(B, A) \cong \mathbf{C}(B, B)
        \end{equation*}{}
    \end{proof}
\end{frame}

\begin{frame}[fragile]
    \begin{block}{The Yoneda Lemma}
        $A$ and $B$ are isomorphic if and only if the sets $\mathbf{C}(A, X) $ and $\mathbf{C}(B, X)$ are naturally isomorphic.
    \end{block}{}
    
    \begin{proof}[Proof ($\Rightarrow$)]
    
        Note that $\mathbf{C}(A,-)$ is a functor $\mathbf{C} \to \mathbf{C}$. Functors preserve isomorphisms. Hence, $\mathbf{C}(A, X) \cong \mathbf{C}(B, X)$ for all $X$.

    \end{proof}
\end{frame}



\section{Representability}

\begin{frame}{Representable Yoneda}
    
Consider the previous statement, that $A \cong B \iff \cat{C}(A, X) \cong \cat{C}(B, X)$ for all $X$. Lets consider just $\cat{C}(A, X)$.
    
\end{frame}

\begin{frame}{Representable Yoneda}
    
In some sense the functor $\cat{C}(A, -)$ is determined by both an object $A \in \cat{C}$, as well as the functor $\cat{C}(A,-)$.
    
\end{frame}

\begin{frame}{Representable Yoneda}
    
Suppose I wanted to generalize the previous Yoneda lemma to any functor from $F \in \homf{C}{Set}$. What would be needed?
    
\end{frame}

\begin{frame}{Representable Yoneda}
    
We would need a the same representing object, of course, but what properties would we need $F$ to have?
    
\end{frame}

\begin{frame}{Representable Yoneda}
    
We have already seen a mechanism that can transform one functor into another: a natural transformation! In fact, we need something slightly stronger than a transformation - we must require that this be a natural isomorphism!
\end{frame}

\begin{frame}{Representable Yoneda}
    
\begin{definition}[Representable Functors]
A functor $F \in \homf{C}{Set}$ is called \textbf{representable} if it is naturally isomorphic to $\cat{C}(A,-)$ for some object $A \in \cat{C}$. A \textbf{representation} of $F$ is a pair $(A, \Phi)$ of its \textbf{representing object}, A, and a natural isomorphism $\Phi : \cat{C}(A,-) \cong F$.

\end{definition}
    
\end{frame}

\begin{frame}{Representable Yoneda}
    
Indeed, this gives us a new, and  characterization of the Yoneda lemma in terms of representable functors. 
    
\end{frame}

\begin{frame}{Representable Yoneda}
    
Representability says that $FX \cong_{\Phi_X} \cat{C}(A,X)$, but what we truly want to prove is that when $ A \cong B$, we have $FA \cong FB$.
    
\end{frame}

\begin{frame}{Representable Yoneda}
    
In fact, we want that if $A \cong B$, then $\cat{C}(A,-) \cong FA$ and  $\cat{C}(B,-) \cong FB$.
    
\end{frame}

\begin{frame}{Representable Yoneda}
    
In philosophical terms, this would allow us to say that whenever a representation $(A, \Phi)$ of $F$ that is isomorphic to some other representation $(B, \Psi)$, then $FA \cong FB$. In order to prove this, we can show that the set of all transformations of $\cat{C}(A,-) \Rightarrow F$ is in correspondence with $FA$.
    
\end{frame}

\begin{frame}{Yoneda Lemma}
    
    \begin{definition}[Yoneda Lemma]
        Let $F \in [\mathbf{C}, \mathbf{Set}]$ be a representable functor, and let $A \in C$. The set of natural transformations $[\mathbf{C}, \mathbf{Set}](\mathbf{C}(A,-), F)$ is in bijection with $FA$ for all $A \in \mathbf{C}$. This bijection associates a morphism (natural transformation) $\alpha: \mathbf{C}(A,-) \Rightarrow F$ to the identity $\alpha(1_A) \in FA$
    \end{definition}{}
\end{frame}

\begin{frame}{Representability}
    It turns out that our work has been about the correspondence between representable functors and natural isomorphisms all along!
\end{frame}{}

%---------------------------------------------------------------------------
% Yoneda Haskell
%---------------------------------------------------------------------------
\begin{frame}
Now that we are familiar with category-theoretic definition of Yoneda Lemma, we will soon see how we can apply it to counting. But first,
\begin{block}{Functors preserve isomorphisms}
If $a \cong b$, then $f~a \cong f~b$ for covariant, contravariant, and invariant functors.
\end{block}
\end{frame}

\begin{frame}[fragile]
Proof that $a \cong b \Rightarrow f~a \cong f~b$ for covariant functors:
\begin{minted}[escapeinside=||,mathescape]{haskell}
toF :: Functor f => f a -> f b
toF fa = fmap to fa
fromF :: Functor f => f b -> f a
fromF fb = fmap from fb
fromTo :: Functor f => f a -> f a
fromTo = from . to
fromTo = (\x -> fmap from x) . (\x -> fmap to x)
fromTo = \x -> fmap from (fmap to x)
fromTo = \x -> fmap (from . to) x
fromTo = identity
\end{minted}
\end{frame}

\begin{frame}{}
\begin{block}{Functors preserve isomorphisms}
If $a \cong b$, then $f~a \cong f~b$ for covariant, contravariant, and invariant functors.
\end{block}

Here are some simple exercises to drive this home:
\begin{enumerate}
    \item Prove that $(\text{Bool}, ()) \to \text{Either}~(\text{Either}~()~())~\text{Void}$ is isomorphic to $\text{Bool} \to \text{Bool}$, and then show that this is isomorphic to a type with four inhabitants.
    \item Prove that $(a \to a \to z) \to z$ is isomorphic to $((Bool \to a) \to z) \to z$.
\end{enumerate}
\end{frame}

\begin{frame}
Finally, we can do Yoneda lemma in Haskell and $\lambda$-calculus:

\begin{block}{Different Yoneda lemmas}
\begin{tabular}{rc}
Covariant functor:     & $(\forall x. (a \to x) \to f~x) \cong f~a$. \\
Contravariant functor: & $(\forall x. (x \to a) \to f~x) \cong f~a$.
\end{tabular}
\end{block}
\end{frame}

\begin{frame}[fragile]
Expressed in Haskell these look like this:
\begin{minted}[escapeinside=||,mathescape]{haskell}
covariant :: Functor f => 
             Iso (forall x. (a -> x) -> f x) (f a)
covariant = Iso (\f -> f identity)
                (\fa -> \f -> fmap f fa)
                
contravariant :: Contravariant f => 
                 Iso (forall x. (x -> a) -> f x) (f a)
contravariant = Iso (\f -> f identity)
                    (\fa -> \f -> contramap f fa)
\end{minted}
\end{frame}

\begin{frame}[fragile]
Let's look at the individual components of the first isomorphism:
\begin{minted}[escapeinside=||,mathescape]{haskell}
to :: (forall x. (a -> x) -> f x) -> (f a)
to f = f id
                
from :: f a -> (forall x. (a -> x) -> f x)
from fa = \f -> fmap f fa
\end{minted}
\end{frame}


\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
fromTo :: Functor f => (forall x. (a -> x) -> f x) ->
                       (forall x. (a -> x) -> f x)
fromTo = from . to
fromTo = (\fa -> \g -> fmap g fa) . 
         (\f -> f id)
fromTo = \f -> \g -> fmap g (f id) 
-- Using parametricity
fromTo = \f -> \g -> f (g . id)
-- Function composition
fromTo = \f -> \g -> f g
-- Eta reduction
fromTo = \f -> f
fromTo = id
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
toFrom :: Functor f => f a -> f a
toFrom = to . from
toFrom = (\f -> f id) . (\fa -> \g -> fmap g fa)
         
toFrom = \fa -> (\g -> fmap g fa) id
toFrom = \fa -> fa
toFrom = id
\end{minted}
\end{frame}

\begin{frame}[fragile]
Let's apply Yoneda lemma ($\forall x. (a \to x) \to f~x \cong f~a$) to a simple example:

\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a. a -> a
  |$\cong$| |$\forall$| a. (() |$\to$| a) -> a
  -- newtype Id a = a
  |$\cong$| |$\forall$| a. (() \to a) -> Id a
  |$\cong$| Id ()
  |$\cong$| ()
\end{minted}

Since () has only one inhabitant, we conclude that $\forall a. a \to a$ has only one inhabitant as well.
\end{frame}

\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a x. (a, x) -> a
    -- uncurrying
    |$\cong$| |$\forall$| a x. x -> a -> a
    -- () -> x $\cong$ x
    |$\cong$| |$\forall$| a x. (() -> x) -> a -> a
    -- Yoneda with newtype F a x = a -> a
    |$\cong$| |$\forall$| a. F a ()
    |$\cong$| |$\forall$| a. a -> a
    -- reusing the proof above
    |$\cong$| ()
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a. (a, a) -> a
    -- (a, a) $\cong$ Bool -> a
    |$\cong$| |$\forall$| a. (Bool -> a) -> a
    -- Yoneda with newtype F x = x
    |$\cong$| Bool
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a. (a, a) -> (a, a)
    -- (a, a) $\cong$ Bool -> (a, a)
    |$\cong$| |$\forall$| a. (Bool -> a) -> (a, a)
    -- Yoneda with newtype F x = (x, x)
    |$\cong$| (Bool, Bool)
    -- Fin 4 is a type with 4 inhabitants.
    |$\cong$| Fin 4
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a b c. (a -> c) -> b -> a -> c
    -- newtype F a b x = b -> a -> x
    |$\cong$| |$\forall$| a b. F a b a
    |$\cong$| |$\forall$| a b. b -> a -> a
    -- reusing one of the above theorems
    |$\cong$| ()
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a b c. (a -> b) -> (b -> c) -> (a -> c)
    -- reorder the arguments
    |$\cong$| |$\forall$| a b c. (b -> c) -> (a -> b) -> a -> c
    -- Yoneda with newtype F a b x = (a -> b) -> a -> x
    |$\cong$| |$\forall$| a b. F a b b
    |$\cong$| |$\forall$| a b. (a -> b) -> a -> b
    -- Yoneda with newtype G a x = a -> x
    |$\cong$| |$\forall$| a. G a a
    |$\cong$| |$\forall$| a. a -> a
    -- reusing the above theorems
    |$\cong$| ()
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a b. (a -> b) -> b -> a -> b
    |$\cong$| |$\forall$| a b. (a -> b) -> (1 -> b) -> a -> b
    -- using pairing
    |$\cong$| |$\forall$| a b. ((a + 1) -> b) -> a -> b
    -- Yoneda with newtype F a x = a -> x
    |$\cong$| |$\forall$| a. F a (a + 1)
    |$\cong$| |$\forall$| a. a -> (a + 1)
    -- a $\cong$ 1 -> a
    |$\cong$| |$\forall$| a. (1 -> a) -> (a + 1)
    -- Yoneda with newtype G x = x + 1
    |$\cong$| G 1
    |$\cong$| 1 + 1
    |$\cong$| 2
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a. (0 -> a) -> a -> 0
    |$\cong$| |$\forall$| a. (0 -> a) -> (1 -> a) -> 0
    |$\cong$| |$\forall$| a. (1 -> a) -> 0
    -- Yoneda with newtype F x = 0
    |$\cong$| F 1
    |$\cong$| 0
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a b. (a -> 0, b) -> 2 |$\times$| b
    |$\cong$| |$\forall$| a b. b -> (a -> 0) -> 2 |$\times$| b
    |$\cong$| |$\forall$| a b. (1 -> b) -> (a -> 0) -> 2 |$\times$| b
    -- Yoneda with newtype F a x = (a -> 0) -> 2 |$\times$| x
    |$\cong$| |$\forall$| a b. F a 1
    |$\cong$| |$\forall$| a b. (a -> 0) -> 2 |$\times$| 1
    -- Add (0 -> a) $\cong$ 1
    |$\cong$| |$\forall$| a. (0 -> a) -> (a -> 0) -> 2
    -- Yoneda with newtype G x = (x -> 0) -> 2
    |$\cong$| G 0
    |$\cong$| (0 -> 0) -> 2
    |$\cong$| 1 -> 2
    |$\cong$| 2
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a. (a -> 0) -> 0
    |$\cong$| |$\forall$| a. (0 -> a) -> (a -> 0) -> 0
    -- Yoneda with newtype G x = (x -> 0) -> 0
    |$\cong$| (0 -> 0) -> 0
    |$\cong$| 1 -> 0
    |$\cong$| 0
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a. (a -> 0) -> a -> 0
    |$\cong$| |$\forall$| a. a -> (a -> 0) -> 0
    -- Yoneda with newtype G x = (x -> 0) -> 0
    |$\cong$| (1 -> 0) -> 0
    |$\cong$| 0 -> 0
    |$\cong$| 0
\end{minted}
\end{frame}

\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a. (a -> 0, a -> 0) -> (a -> 0)
    |$\cong$| |$\forall$| a. a -> (a -> 0, a -> 0) -> 0
    |$\cong$| |$\forall$| a. (1 -> a) -> (a -> 0, a -> 0) -> 0
    |$\cong$| (1 -> 0, 1 -> 0) -> 0
    |$\cong$| (0, 0) -> 0
    |$\cong$| 0 -> 0
    |$\cong$| 1
\end{minted}
\end{frame}


\begin{frame}[fragile]
\begin{minted}[escapeinside=||,mathescape]{haskell}
|$\forall$| a b. (a -> b) -> Maybe a -> Maybe b
    -- Yoneda with newtype F a x = Maybe a -> Maybe x
    |$\cong$| |$\forall$| a. Maybe a -> Maybe a
    -- Maybe's definition
    |$\cong$| |$\forall$| a. (1 + a) -> Maybe a
    -- Pairing
    |$\cong$| |$\forall$| a. (1 -> Maybe a) |$\times$| (a -> Maybe a)
\end{minted}

We've hit an impasse. We can't apply Yoneda Lemma directly, since $a$ occurs both in positive and negative positions.
\end{frame}

\begin{frame}[fragile]
We need:
\begin{block}{Distributing $\forall$ over $\times$.}
    \begin{center}
        $\forall x. f x \times g x \cong (\forall x. f x) \times (\forall x. g x)$
    \end{center}
\end{block}
and (\em non-trivial)
\begin{block}{Distributing $\forall$ over $+$.}
    \begin{center}
        $\forall x. f x + g x \cong (\forall x. f x) + (\forall x. g x)$
    \end{center}
\end{block}
\end{frame}

\begin{frame}[fragile]
Proof for $\forall x. f x \times g x \cong (\forall x. f x) \times (\forall x. g x)$:
\begin{minted}[escapeinside=||,mathescape]{haskell}
-- Dependent types are for clarity...
to :: ((x :: *) -> (f x, g x)) 
   -> ((x :: *) -> f x, (x :: *) -> g x)
to pair = (\t -> fst (pair t), \t -> snd (pair t))

from :: ((x :: *) -> f x, (x :: *) -> g x) 
     -> ((x :: *) -> (f x, g x))
from pair = (\t -> (fst pair t, snd pair t))
\end{minted}
\end{frame}

\begin{frame}[fragile]
Proof for $\forall x. f x + g x \cong (\forall x. f x) + (\forall x. g x)$:
\begin{minted}[escapeinside=||,mathescape]{haskell}
to :: ((x :: *) -> Either (f x) (g x)) 
   -> Either ((x :: *) -> f x) ((x :: *) -> g x)
-- Using parametricity here:
to e = case (e ()) of
  Left  fx -> Left  (\t -> (unsafeCoerce fx :: f t))
  Right gx -> Right (\t -> (unsafeCoerce gx :: f t))

from :: Either ((x :: *) -> f x) ((x :: *) -> g x)
     -> ((x :: *) -> Either (f x) (g x))
from (Left fx)  = \t -> Left  (fx t)
from (Right gx) = \t -> Right (gx t)
\end{minted}
\end{frame}

\begin{frame}[fragile]
Let's back to Maybe a $\rightarrow$ Maybe a.
\begin{minted}[escapeinside=||,mathescape]{haskell}
    |$\cong$| |$\forall$| a. (1 -> Maybe a) |$\times$| (a -> Maybe a)
    -- Distributing $\forall$ over $\times$
    |$\cong$| (|$\forall$| a. Maybe a) |$\times$| (|$\forall$| a. a -> Maybe a)
    -- Maybe's definition
    |$\cong$| (|$\forall$| a. (1 + a)) |$\times$| (|$\forall$| a. a -> Maybe a)
    -- 0 -> a introduction (as a unit)
    |$\cong$| (|$\forall$| a. (0 -> a) -> (1 + a)) |$\times$| (|$\forall$| a. a -> Maybe a)
    -- Yoneda lemma with newtype F x = 1 + x
    |$\cong$| (1 + 0) |$\times$| (|$\forall$| a. a -> Maybe a)
    -- Simplifying via x + 0 = x and 1 $\times$ x = x
    |$\cong$| |$\forall$| a. a -> Maybe a
    -- unit introduction and Maybe's definition
    |$\cong$| |$\forall$| a. (1 -> a) -> (1 + a)
    -- Yoneda lemma with f x = 1 + x
    |$\cong$| 2
\end{minted}
\end{frame}

\begin{frame}[fragile]
Exercises: 
\begin{enumerate}
    \item Explicitly list the two inhabitants of $\forall~a~b. (a \to b) \to \text{Maybe}~a \to \text{Maybe}~b$.
    \item Prove that $\forall~a~z. (a \to a \to z) \to z$ is isomorphic to $(a, a)$.
\end{enumerate}
\end{frame}

\subsection{Universal Properties}

\begin{frame}{Universal Properties}

We have learned a great deal about yoneda, and we have shown some surprising results that begin to touch upon how it can be used to "count" type inhabitants. 
\end{frame}

\begin{frame}{Universal Properties}

So far, we have shown that currying, pairing, and exponentiation have an interesting arithmetic. 

\end{frame}

\begin{frame}{Universal Properties}

How do we realize these properties categorically? 

\end{frame}

\begin{frame}{Universal Properties}

In a sense, these properties are \textit{universal} in that they are very "natural" actions to take - they manifest properties of maps to and from products, coproducts, and exponents.

\end{frame}

\begin{frame}{Universal Properties}

Because it's often germane to our studies to look at the hom-sets of maps to and from these objects in order to learn more about them, lets take a look at products and coproducts

\end{frame}

\begin{frame}{Universal Properties}
    Suppose we wanted to talk about $\mathbf{C}(A \times B, X)$. 
\end{frame}

\begin{frame}{Universal Properties}
    What does a function $A \times B \to X$ look like? 
\end{frame}{}

\begin{frame}{Universal Properties}
    Lets start with the categorical definition of a Product.
\end{frame}

\begin{frame}{Universal Properties}
    \begin{definition}{Product}
        Let $\mathbf{C}$ be a category, and let $X, Y \in \mathbf{C}$. A product $P$ is an object of $\mathbf{C}$ together with functions $\pi_X: P \to X$ and $\pi_Y: P \to Y$ such that the following holds:  
            \begin{itemize}
                \item For any other $N \in \mathbf{C}$ and morphisms $f_X: N \to X$ and $f_Y : N \to Y$, we have that a unique, induced morphism $f : N \to P$ such that $f_X = \pi_Xf$ and $f_Y = \pi_Yf$. 
            \end{itemize}
    \end{definition}
    $P$ is usually denoted $X \times Y$.
\end{frame}{}

\begin{frame}[fragile]
More succinctly, the object $X \times Y$ in the following diagram commutes for any given $N$ and morphisms $f_Y, f_X$: 
    
\begin{center}
    \begin{tikzcd}
        & & X  \\
        N 
          \arrow[r, dashed, "f", description]
          \arrow[urr, "f_Y", bend left] 
          \arrow[drr, "f_X", bend right] & 
        X \times Y \arrow[ur, "\pi_X"] \arrow[dr, "\pi_Y"] \\ & & 
        Y
    \end{tikzcd}{}
\end{center}{}

\end{frame}

\begin{frame}{Universal Properties}
    A function $f: A \times B \to X$ contains the following data: 
\end{frame}{}

\begin{frame}{Meditations on $\times$}

    A function $f: A \times B \to X$ contains the following data: 
    \begin{block}{}
    
        \begin{itemize}
            \item For $A \times B$, the function $f$ must specify an element $f(a,b) \in X$.
            
            \item Additionally, for any $b \in A$, the function $f(-,b)$ must specify a function $A \to X$ sending $a$ to $f(a,b)$
        \end{itemize}{}
    \end{block}{}
\end{frame}{}

\begin{frame}{Universal Properties}
    Thus, all that needed in order to define a function $A \times B \to X$ is the data that sends a $b \in A$ to the partial application of the function $f$ to form a function $B \to \mathbf{C}(A, X): a \mapsto f(-,b)$ which takes a $a$ and produces a $x \in C$ by completing the partial evaluation $f(a,b)$.
\end{frame}{}

\begin{frame}{Universal Properties}
    This should look familiar. \textit{Because it's currying}!. The full statement of currying is the following:
    
\begin{block}{Currying}
\begin{equation*}
    \mathbf{C}(A \times B, C) \cong \mathbf{C}(B, \mathbf{C}(A, X))
\end{equation*}{}
\end{block}{}
\end{frame}

\begin{frame}{Currying}
    Let's abstract that a bit. Suppose we are working exclusively in a category $\cat{C}$ with products and exponents.
\end{frame}

\begin{frame}{Currying}
   There are two functors in play, and their hom sets are isomorphic. The product functor $A \times - : \cat{C} \to \cat{C}$, and an exponential functor $A^{(-)}: \cat{C} \to \cat{C}$. 
\end{frame}

\begin{frame}{Currying}
   By taking $\cat{C}(B, C) :\equiv B^C$, statement of currying can  be refactored into the following: $\cat{C}(A \times B, C) \cong \cat{C}(B, C^A)$.
\end{frame}

\begin{frame}{Currying}
   Note that if we remove the parameters of the functor, then we are left with a statement about the natural isomorphism whose components characterize currying: 
   
   \begin{center}
   	\begin{equation*}
		\Phi_{X,Y} : \cat{C}(A \times X, Y) \cong \cat{C}(A, Y^X)
	\end{equation*}
   \end{center}
\end{frame}

\begin{frame}{Adjunction}
   This is what is known as an \textbf{adjunction}, which characterizes the logical dual of a statement category theory. 
\end{frame}

\begin{frame}{Adjunctions}
   \begin{definition}[Adjunction]
   	Let $F: \cat{C} \to \cat{D}$ and $G: \cat{D} \to \cat{C}$ be functors. We say that $F$ and $G$ are \textbf{adjoint} (left and right adjoint resp.), or notationally $F \dashv G$ if there exists a natural isomorphism $\Phi : D(F-,=) \cong C(-, G=)$. The components of $\Phi$ are set bijections $\Phi_{X,Y} : \cat{D}(FX, Y) \cong \cat{C}(X, GY)$
   \end{definition}
\end{frame}

\begin{frame}{Adjunctions}
   In category theory, one of the strongest statements one can make is that two statements are logical "opposites". It is in fact the case that universal properties of our products and coproducts are characterized by relevant statements and their logical opposites. I fact, products and coproducts are dual themselves!
\end{frame}

\begin{frame}{Adjunctions}
   It is a theorem which we will leave to the optional slide set that states that coproducts are left adjoint to a diagonal functor, and products are right adjoint to it. 
\end{frame}

\begin{frame}{Pairing}
    Lets see what $B + C \to X$ looks like and see if we can do the same thing!
\end{frame}{}

\begin{frame}{Pairing}
    First, let us define coproducts. 
\end{frame}{}

\begin{frame}{Pairing}
    \begin{definition}{Pairing}
        Let $\cat{C}$ be a category and let $X, Y \in \cat{C}$. A \textit{coproduct} $C$ is an object of $\cat{C}$ together with functions $i_X : X \to C$ and $i_Y: Y \to C$ such that the following holds: 
        
        \begin{itemize}
            \item For any other $N \in \cat{C}$, and morphisms $f_X: X \to N$ and $f_Y: Y \to N$, there is a unique, induced morphism $f: C \to N$ such that $f_X = fi_X$ and $f_Y = fi_Y$.
        \end{itemize}{}
    \end{definition}{}
    
    The coproduct of $C$ is generally denoted $X + Y$
\end{frame}{}

\begin{frame}[fragile]
    Or, more succinctly, the following diagram commutes for any given $N$ and morphisms $f_Y, f_X$: 
    
\begin{center}
    \begin{tikzcd}
        X  
          \arrow[dr, "i_X"]
          \arrow[drr, "f_X", bend left]  \\
        & X + Y \arrow[r, dashed, "f", description] 
        & N \\
        Y 
          \arrow[ur, "i_Y"]
          \arrow[urr, "f_Y", bend right]
    \end{tikzcd}{}
\end{center}{}

\end{frame}

\begin{frame}{Pairing}
    Note that all that's needed to define a function $f: B + C \to X$ is then to define a pair of functions $g: B \to X$ and $h: C \to X$ associating each $b \in B$ and $c \in C$ with an element of $X$. 

\end{frame}

\begin{frame}{Pairing}
Thus, we obtain the following: 

\begin{block}{Pairing}
    \begin{equation*}
        \mathbf{C}(B + C, X) \cong \mathbf{C}(B, X) \times \mathbf{C}(C, X)
    \end{equation*}{}
\end{block}{}
\end{frame}

\begin{frame}{Pairing}
    Notice what happens when we "erase" the parameters of the pairing isomorphism just as we did for currying, and consider the natural isomorphism lying underneath. 
\end{frame}

\begin{frame}{Pairing}
    Again, there are two functors belying this statement - the coproduct functor $Y + (-): \cat{C} \to \cat{C}$, but other one is a little different. If we note that a the product of hom-sets gives us a pair of morphisms $f \times g$, then we can also note that this product of hom-sets operates on products of elements. In fact, we have $(f \times g): (B, C) \to (X,X)$. Ergo, we have $f \times g \in \cat{[C \times C]}((B,C), (X,X))$.
\end{frame}

\begin{frame}{Pairing}
    Therefore our functor on the right is one that takes any $X \in \cat{C}$ to its diagonal pair, $\Delta: \cat{C} \to \cat{C} \times \cat{C}$, and the components of our isomorphism take the form of 
    
    \begin{center}
    	\begin{equation*}
		\Phi_{X,Y} : \cat{C}(B + X, Y) \to \cat{C}(B \times X, \Delta Y) \cong \cat{C}(B, Y) \times \cat{C}(X, Y)
	\end{equation*}
    \end{center}
\end{frame}

\begin{frame}{Pairing}
    And the adjunction is complete.
\end{frame}

\begin{frame}{Representability}
    Note the duality of it all! The diagrams obtained in the previous slides are dual universal properties of the product and coproduct respectively.
\end{frame}

\begin{frame}{Exercise}

Can you show that $(B \times C)^A \cong B^A \times C^A$?
\end{frame}

\section{Example}
\subsection{}
    
\begin{frame}{Proof}
    Lets prove the following:
    
    \begin{center}
        \begin{equation*}
            a \times (b + c) = (a \times b) + (a \times c)
        \end{equation*}
    \end{center}

\end{frame}

\end{document}
